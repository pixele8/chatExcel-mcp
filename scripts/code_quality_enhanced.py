#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºçš„ä»£ç è´¨é‡æ£€æŸ¥è„šæœ¬

é›†æˆå¤šç§é™æ€åˆ†æå·¥å…·ï¼Œæä¾›å…¨é¢çš„ä»£ç è´¨é‡è¯„ä¼°ã€‚
æ”¯æŒç”Ÿæˆè¯¦ç»†æŠ¥å‘Šå’Œä¿®å¤å»ºè®®ï¼Œé›†æˆ pre-commit é’©å­ã€‚

ä½¿ç”¨æ–¹æ³•:
    python scripts/code_quality_enhanced.py [é€‰é¡¹]

é€‰é¡¹:
    --fix: è‡ªåŠ¨ä¿®å¤å¯ä¿®å¤çš„é—®é¢˜
    --report: ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
    --config: æŒ‡å®šé…ç½®æ–‡ä»¶è·¯å¾„
    --exclude: æ’é™¤ç‰¹å®šç›®å½•æˆ–æ–‡ä»¶
    --install-hooks: å®‰è£… pre-commit é’©å­
    --run-hooks: è¿è¡Œ pre-commit é’©å­
"""

import os
import sys
import subprocess
import json
import time
import argparse
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from datetime import datetime


@dataclass
class QualityResult:
    """è´¨é‡æ£€æŸ¥ç»“æœ"""
    tool: str
    status: str  # 'success', 'warning', 'error', 'skipped'
    score: Optional[float] = None
    issues: List[Dict[str, Any]] = None
    execution_time: float = 0.0
    output: str = ""
    error: str = ""


class CodeQualityChecker:
    """ä»£ç è´¨é‡æ£€æŸ¥å™¨"""
    
    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.results: List[QualityResult] = []
        self.config = self._load_config()
    
    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®"""
        config_file = self.project_root / "pyproject.toml"
        if config_file.exists():
            try:
                import toml
                with open(config_file, 'r', encoding='utf-8') as f:
                    return toml.load(f)
            except ImportError:
                print("è­¦å‘Š: æœªå®‰è£… toml åº“ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            except Exception as e:
                print(f"è­¦å‘Š: è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        
        return {
            "tool": {
                "black": {"line-length": 88, "target-version": ["py311"]},
                "isort": {"profile": "black", "line_length": 88},
                "flake8": {"max-line-length": 88, "ignore": ["E203", "W503"]},
                "mypy": {"python_version": "3.11", "strict": True},
                "bandit": {"exclude_dirs": ["tests", "venv", ".venv"]}
            }
        }
    
    def _run_command(self, cmd: List[str], cwd: Optional[Path] = None) -> tuple[int, str, str]:
        """è¿è¡Œå‘½ä»¤å¹¶è¿”å›ç»“æœ"""
        try:
            result = subprocess.run(
                cmd,
                cwd=cwd or self.project_root,
                capture_output=True,
                text=True,
                timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
            )
            return result.returncode, result.stdout, result.stderr
        except subprocess.TimeoutExpired:
            return -1, "", "å‘½ä»¤æ‰§è¡Œè¶…æ—¶"
        except Exception as e:
            return -1, "", str(e)
    
    def _check_tool_available(self, tool: str) -> bool:
        """æ£€æŸ¥å·¥å…·æ˜¯å¦å¯ç”¨"""
        try:
            result = subprocess.run(
                [tool, "--version"],
                capture_output=True,
                text=True,
                timeout=10
            )
            return result.returncode == 0
        except:
            return False
    
    def check_black(self) -> QualityResult:
        """æ£€æŸ¥ä»£ç æ ¼å¼åŒ– (Black)"""
        start_time = time.time()
        
        if not self._check_tool_available("black"):
            return QualityResult(
                tool="black",
                status="skipped",
                error="Black æœªå®‰è£…",
                execution_time=time.time() - start_time
            )
        
        # æ£€æŸ¥æ ¼å¼åŒ–
        cmd = ["black", "--check", "--diff", "--color", "."]
        returncode, stdout, stderr = self._run_command(cmd)
        
        if returncode == 0:
            status = "success"
            score = 100.0
        else:
            status = "warning"
            score = 70.0  # éœ€è¦æ ¼å¼åŒ–ä½†ä¸æ˜¯é”™è¯¯
        
        return QualityResult(
            tool="black",
            status=status,
            score=score,
            output=stdout,
            error=stderr,
            execution_time=time.time() - start_time
        )
    
    def check_isort(self) -> QualityResult:
        """æ£€æŸ¥å¯¼å…¥æ’åº (isort)"""
        start_time = time.time()
        
        if not self._check_tool_available("isort"):
            return QualityResult(
                tool="isort",
                status="skipped",
                error="isort æœªå®‰è£…",
                execution_time=time.time() - start_time
            )
        
        cmd = ["isort", "--check-only", "--diff", "."]
        returncode, stdout, stderr = self._run_command(cmd)
        
        if returncode == 0:
            status = "success"
            score = 100.0
        else:
            status = "warning"
            score = 80.0
        
        return QualityResult(
            tool="isort",
            status=status,
            score=score,
            output=stdout,
            error=stderr,
            execution_time=time.time() - start_time
        )
    
    def check_flake8(self) -> QualityResult:
        """æ£€æŸ¥ä»£ç é£æ ¼ (Flake8)"""
        start_time = time.time()
        
        if not self._check_tool_available("flake8"):
            return QualityResult(
                tool="flake8",
                status="skipped",
                error="flake8 æœªå®‰è£…",
                execution_time=time.time() - start_time
            )
        
        cmd = ["flake8", "--format=json", "."]
        returncode, stdout, stderr = self._run_command(cmd)
        
        issues = []
        if stdout:
            try:
                # Flake8 JSON æ ¼å¼è¾“å‡º
                for line in stdout.strip().split('\n'):
                    if line:
                        issue = json.loads(line)
                        issues.append(issue)
            except json.JSONDecodeError:
                # å¦‚æœä¸æ˜¯ JSON æ ¼å¼ï¼ŒæŒ‰è¡Œè§£æ
                issues = [{'message': line} for line in stdout.strip().split('\n') if line]
        
        # è®¡ç®—åˆ†æ•°
        if len(issues) == 0:
            status = "success"
            score = 100.0
        elif len(issues) <= 10:
            status = "warning"
            score = max(70.0, 100.0 - len(issues) * 3)
        else:
            status = "error"
            score = max(30.0, 100.0 - len(issues) * 2)
        
        return QualityResult(
            tool="flake8",
            status=status,
            score=score,
            issues=issues,
            output=stdout,
            error=stderr,
            execution_time=time.time() - start_time
        )
    
    def check_mypy(self) -> QualityResult:
        """æ£€æŸ¥ç±»å‹æ³¨è§£ (MyPy)"""
        start_time = time.time()
        
        if not self._check_tool_available("mypy"):
            return QualityResult(
                tool="mypy",
                status="skipped",
                error="mypy æœªå®‰è£…",
                execution_time=time.time() - start_time
            )
        
        cmd = ["mypy", "--json-report", "/tmp/mypy_report", "."]
        returncode, stdout, stderr = self._run_command(cmd)
        
        issues = []
        # è§£æ MyPy è¾“å‡º
        if stderr:
            for line in stderr.strip().split('\n'):
                if line and ':' in line:
                    parts = line.split(':', 3)
                    if len(parts) >= 4:
                        issues.append({
                            'file': parts[0],
                            'line': parts[1],
                            'column': parts[2] if parts[2].isdigit() else '0',
                            'message': parts[3].strip()
                        })
        
        # è®¡ç®—åˆ†æ•°
        if len(issues) == 0:
            status = "success"
            score = 100.0
        elif len(issues) <= 5:
            status = "warning"
            score = max(80.0, 100.0 - len(issues) * 4)
        else:
            status = "error"
            score = max(50.0, 100.0 - len(issues) * 3)
        
        return QualityResult(
            tool="mypy",
            status=status,
            score=score,
            issues=issues,
            output=stdout,
            error=stderr,
            execution_time=time.time() - start_time
        )
    
    def check_bandit(self) -> QualityResult:
        """æ£€æŸ¥å®‰å…¨é—®é¢˜ (Bandit)"""
        start_time = time.time()
        
        if not self._check_tool_available("bandit"):
            return QualityResult(
                tool="bandit",
                status="skipped",
                error="bandit æœªå®‰è£…",
                execution_time=time.time() - start_time
            )
        
        cmd = ["bandit", "-r", ".", "-f", "json", "-x", "tests,venv,.venv"]
        returncode, stdout, stderr = self._run_command(cmd)
        
        issues = []
        if stdout:
            try:
                data = json.loads(stdout)
                issues = data.get('results', [])
            except json.JSONDecodeError:
                pass
        
        # è®¡ç®—åˆ†æ•° - å®‰å…¨é—®é¢˜æ›´ä¸¥é‡
        high_severity = len([i for i in issues if i.get('issue_severity') == 'HIGH'])
        medium_severity = len([i for i in issues if i.get('issue_severity') == 'MEDIUM'])
        low_severity = len([i for i in issues if i.get('issue_severity') == 'LOW'])
        
        if high_severity > 0:
            status = "error"
            score = max(20.0, 100.0 - high_severity * 20 - medium_severity * 10 - low_severity * 5)
        elif medium_severity > 0:
            status = "warning"
            score = max(60.0, 100.0 - medium_severity * 10 - low_severity * 5)
        elif low_severity > 0:
            status = "warning"
            score = max(80.0, 100.0 - low_severity * 5)
        else:
            status = "success"
            score = 100.0
        
        return QualityResult(
            tool="bandit",
            status=status,
            score=score,
            issues=issues,
            output=stdout,
            error=stderr,
            execution_time=time.time() - start_time
        )
    
    def check_pytest(self) -> QualityResult:
        """è¿è¡Œæµ‹è¯• (Pytest)"""
        start_time = time.time()
        
        if not self._check_tool_available("pytest"):
            return QualityResult(
                tool="pytest",
                status="skipped",
                error="pytest æœªå®‰è£…",
                execution_time=time.time() - start_time
            )
        
        cmd = ["pytest", "--tb=short", "-v", "--json-report", "--json-report-file=/tmp/pytest_report.json"]
        returncode, stdout, stderr = self._run_command(cmd)
        
        # è§£ææµ‹è¯•ç»“æœ
        test_results = {}
        try:
            with open('/tmp/pytest_report.json', 'r') as f:
                test_results = json.load(f)
        except:
            pass
        
        total_tests = test_results.get('summary', {}).get('total', 0)
        passed_tests = test_results.get('summary', {}).get('passed', 0)
        failed_tests = test_results.get('summary', {}).get('failed', 0)
        
        if total_tests == 0:
            status = "warning"
            score = 50.0  # æ²¡æœ‰æµ‹è¯•
        elif failed_tests == 0:
            status = "success"
            score = 100.0
        else:
            status = "error"
            score = max(30.0, (passed_tests / total_tests) * 100)
        
        return QualityResult(
            tool="pytest",
            status=status,
            score=score,
            issues=[],
            output=stdout,
            error=stderr,
            execution_time=time.time() - start_time
        )
    
    def run_all_checks(self) -> List[QualityResult]:
        """è¿è¡Œæ‰€æœ‰æ£€æŸ¥"""
        print("ğŸ” å¼€å§‹ä»£ç è´¨é‡æ£€æŸ¥...")
        
        checks = [
            ("ä»£ç æ ¼å¼åŒ–", self.check_black),
            ("å¯¼å…¥æ’åº", self.check_isort),
            ("ä»£ç é£æ ¼", self.check_flake8),
            ("ç±»å‹æ£€æŸ¥", self.check_mypy),
            ("å®‰å…¨æ£€æŸ¥", self.check_bandit),
            ("å•å…ƒæµ‹è¯•", self.check_pytest)
        ]
        
        for name, check_func in checks:
            print(f"  â³ æ£€æŸ¥ {name}...")
            result = check_func()
            self.results.append(result)
            
            # æ˜¾ç¤ºç»“æœ
            if result.status == "success":
                print(f"  âœ… {name}: é€šè¿‡ (åˆ†æ•°: {result.score:.1f})")
            elif result.status == "warning":
                print(f"  âš ï¸  {name}: è­¦å‘Š (åˆ†æ•°: {result.score:.1f})")
            elif result.status == "error":
                print(f"  âŒ {name}: é”™è¯¯ (åˆ†æ•°: {result.score:.1f})")
            else:
                print(f"  â­ï¸  {name}: è·³è¿‡ ({result.error})")
        
        return self.results
    
    def generate_report(self) -> Dict[str, Any]:
        """ç”ŸæˆæŠ¥å‘Š"""
        total_score = 0.0
        valid_scores = 0
        
        for result in self.results:
            if result.score is not None:
                total_score += result.score
                valid_scores += 1
        
        average_score = total_score / valid_scores if valid_scores > 0 else 0.0
        
        # ç¡®å®šæ€»ä½“çŠ¶æ€
        if average_score >= 90:
            overall_status = "excellent"
        elif average_score >= 80:
            overall_status = "good"
        elif average_score >= 70:
            overall_status = "fair"
        else:
            overall_status = "poor"
        
        return {
            "timestamp": datetime.now().isoformat(),
            "overall_score": average_score,
            "overall_status": overall_status,
            "total_checks": len(self.results),
            "passed_checks": len([r for r in self.results if r.status == "success"]),
            "warning_checks": len([r for r in self.results if r.status == "warning"]),
            "failed_checks": len([r for r in self.results if r.status == "error"]),
            "skipped_checks": len([r for r in self.results if r.status == "skipped"]),
            "results": [
                {
                    "tool": r.tool,
                    "status": r.status,
                    "score": r.score,
                    "execution_time": r.execution_time,
                    "issues_count": len(r.issues) if r.issues else 0,
                    "error": r.error if r.error else None
                }
                for r in self.results
            ]
        }
    
    def save_report(self, report: Dict[str, Any], output_file: Path):
        """ä¿å­˜æŠ¥å‘Š"""
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        print(f"ğŸ“Š æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")


def install_pre_commit_hooks():
    """å®‰è£… pre-commit é’©å­"""
    print("ğŸ”§ å®‰è£… pre-commit é’©å­...")
    
    try:
        # æ£€æŸ¥ pre-commit æ˜¯å¦å·²å®‰è£…
        result = subprocess.run(
            ["pre-commit", "--version"],
            capture_output=True,
            text=True,
            check=False
        )
        
        if result.returncode != 0:
            print("ğŸ“¦ å®‰è£… pre-commit...")
            subprocess.run(["pip", "install", "pre-commit"], check=True)
        
        # å®‰è£…é’©å­
        subprocess.run(["pre-commit", "install"], check=True)
        subprocess.run(["pre-commit", "install", "--hook-type", "commit-msg"], check=True)
        
        print("âœ… Pre-commit é’©å­å®‰è£…æˆåŠŸï¼")
        return True
        
    except subprocess.CalledProcessError as e:
        print(f"âŒ Pre-commit é’©å­å®‰è£…å¤±è´¥: {e}")
        return False
    except Exception as e:
        print(f"ğŸ’¥ å®‰è£…è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return False


def run_pre_commit_hooks():
    """è¿è¡Œ pre-commit é’©å­"""
    print("ğŸš€ è¿è¡Œ pre-commit é’©å­...")
    
    try:
        result = subprocess.run(
            ["pre-commit", "run", "--all-files"],
            capture_output=True,
            text=True,
            check=False
        )
        
        print(result.stdout)
        if result.stderr:
            print(result.stderr)
        
        if result.returncode == 0:
            print("âœ… æ‰€æœ‰ pre-commit é’©å­æ£€æŸ¥é€šè¿‡ï¼")
            return True
        else:
            print("âŒ Pre-commit é’©å­æ£€æŸ¥å‘ç°é—®é¢˜ã€‚")
            return False
            
    except FileNotFoundError:
        print("âŒ Pre-commit æœªå®‰è£…ï¼Œè¯·å…ˆè¿è¡Œ --install-hooks")
        return False
    except Exception as e:
        print(f"ğŸ’¥ è¿è¡Œé’©å­æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="ChatExcel MCP é¡¹ç›®ä»£ç è´¨é‡æ£€æŸ¥å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
    python scripts/code_quality_enhanced.py --fix --report
    python scripts/code_quality_enhanced.py --exclude tests/ --config custom.ini
    python scripts/code_quality_enhanced.py --install-hooks
    python scripts/code_quality_enhanced.py --run-hooks
        """
    )
    
    parser.add_argument(
        "--fix", 
        action="store_true", 
        help="è‡ªåŠ¨ä¿®å¤å¯ä¿®å¤çš„é—®é¢˜"
    )
    parser.add_argument(
        "--report", 
        action="store_true", 
        help="ç”Ÿæˆè¯¦ç»†çš„è´¨é‡æŠ¥å‘Š"
    )
    parser.add_argument(
        "--config", 
        type=str, 
        help="æŒ‡å®šé…ç½®æ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--exclude", 
        type=str, 
        nargs="*", 
        default=["build/", "dist/", ".venv/", "__pycache__/"],
        help="æ’é™¤çš„ç›®å½•æˆ–æ–‡ä»¶æ¨¡å¼"
    )
    parser.add_argument(
        "--install-hooks",
        action="store_true",
        help="å®‰è£… pre-commit é’©å­"
    )
    parser.add_argument(
        "--run-hooks",
        action="store_true",
        help="è¿è¡Œ pre-commit é’©å­"
    )
    
    args = parser.parse_args()
    
    # å¤„ç† pre-commit ç›¸å…³æ“ä½œ
    if args.install_hooks:
        success = install_pre_commit_hooks()
        sys.exit(0 if success else 1)
    
    if args.run_hooks:
        success = run_pre_commit_hooks()
        sys.exit(0 if success else 1)
    
    # åŸæœ‰çš„ä»£ç è´¨é‡æ£€æŸ¥é€»è¾‘
    project_root = Path(__file__).parent.parent
    checker = CodeQualityChecker(project_root)
    
    # è¿è¡Œæ£€æŸ¥
    results = checker.run_all_checks()
    
    # ç”ŸæˆæŠ¥å‘Š
    report = checker.generate_report()
    
    # ä¿å­˜æŠ¥å‘Š
    reports_dir = project_root / "reports"
    reports_dir.mkdir(exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_file = reports_dir / f"code_quality_{timestamp}.json"
    checker.save_report(report, report_file)
    
    # æ˜¾ç¤ºæ€»ç»“
    print("\n" + "="*50)
    print("ğŸ“‹ ä»£ç è´¨é‡æ£€æŸ¥æ€»ç»“")
    print("="*50)
    print(f"æ€»ä½“åˆ†æ•°: {report['overall_score']:.1f}/100")
    print(f"æ€»ä½“çŠ¶æ€: {report['overall_status']}")
    print(f"é€šè¿‡æ£€æŸ¥: {report['passed_checks']}/{report['total_checks']}")
    
    if report['warning_checks'] > 0:
        print(f"è­¦å‘Šæ£€æŸ¥: {report['warning_checks']}")
    if report['failed_checks'] > 0:
        print(f"å¤±è´¥æ£€æŸ¥: {report['failed_checks']}")
    if report['skipped_checks'] > 0:
        print(f"è·³è¿‡æ£€æŸ¥: {report['skipped_checks']}")
    
    # æç¤ºç”¨æˆ·å¯ä»¥å®‰è£… pre-commit é’©å­
    if report['overall_score'] >= 80:
        print("\nğŸ’¡ æç¤º: å¯ä»¥è¿è¡Œ 'python scripts/code_quality_enhanced.py --install-hooks' å®‰è£… pre-commit é’©å­")
    
    # è¿”å›é€‚å½“çš„é€€å‡ºç 
    if report['failed_checks'] > 0:
        sys.exit(1)
    elif report['warning_checks'] > 0:
        sys.exit(2)
    else:
        sys.exit(0)


if __name__ == "__main__":
    main()
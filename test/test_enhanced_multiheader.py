#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºå¤šçº§åˆ—å¤´æ£€æµ‹åŠŸèƒ½æµ‹è¯•

æœ¬æµ‹è¯•æ–‡ä»¶éªŒè¯ enhanced_multiheader_detector.py ä¸­çš„å¢å¼ºåŠŸèƒ½ï¼š
1. æ™ºèƒ½å¤´éƒ¨å€™é€‰æ£€æµ‹
2. ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„ç½®ä¿¡åº¦è®¡ç®—
3. åŠ¨æ€é˜ˆå€¼è°ƒæ•´
4. å‡é˜³æ€§è¿‡æ»¤
5. å¤šç»´åº¦åˆ†æ
"""

import sys
import os
import unittest
from unittest.mock import Mock, patch
import pandas as pd
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

try:
    from enhanced_multiheader_detector import EnhancedMultiHeaderDetector
except ImportError as e:
    print(f"å¯¼å…¥é”™è¯¯: {e}")
    print("è¯·ç¡®ä¿ enhanced_multiheader_detector.py æ–‡ä»¶å­˜åœ¨")
    sys.exit(1)


class TestEnhancedMultiHeaderDetector(unittest.TestCase):
    """å¢å¼ºå¤šçº§åˆ—å¤´æ£€æµ‹å™¨æµ‹è¯•ç±»"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        # åˆ›å»ºä¸´æ—¶æµ‹è¯•æ–‡ä»¶è·¯å¾„
        self.test_file_path = "/tmp/test_data.xlsx"
        self.detector = EnhancedMultiHeaderDetector(self.test_file_path)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ® - å¤šçº§è¡¨å¤´ç¤ºä¾‹
        self.test_data = {
            'A': ['', '', 'é”€å”®æ•°æ®', 'äº§å“A', 'æ•°é‡', '100', '120', '90'],
            'B': ['', '', 'é”€å”®æ•°æ®', 'äº§å“A', 'é‡‘é¢', '1000', '1200', '900'],
            'C': ['', '', 'é”€å”®æ•°æ®', 'äº§å“B', 'æ•°é‡', '80', '95', '110'],
            'D': ['', '', 'é”€å”®æ•°æ®', 'äº§å“B', 'é‡‘é¢', '800', '950', '1100'],
            'E': ['', '', 'æˆæœ¬æ•°æ®', 'äº§å“A', 'æˆæœ¬', '600', '720', '540'],
            'F': ['', '', 'æˆæœ¬æ•°æ®', 'äº§å“B', 'æˆæœ¬', '480', '570', '660']
        }
        
        self.df = pd.DataFrame(self.test_data)
        
    def test_detect_header_candidates_enhanced(self):
        """æµ‹è¯•å¢å¼ºçš„å¤´éƒ¨å€™é€‰æ£€æµ‹"""
        print("\n=== æµ‹è¯•å¢å¼ºçš„å¤´éƒ¨å€™é€‰æ£€æµ‹ ===")
        
        # å°†DataFrameè½¬æ¢ä¸ºåŸå§‹æ•°æ®æ ¼å¼
        raw_data = []
        for i in range(len(self.df)):
            row = []
            for col in self.df.columns:
                row.append(self.df.iloc[i][col])
            raw_data.append(row)
            
        print(f"\næµ‹è¯•æ•°æ® ({len(raw_data)} è¡Œ):")
        for i, row in enumerate(raw_data[:5]):  # åªæ˜¾ç¤ºå‰5è¡Œ
            print(f"è¡Œ {i}: {row}")
            
        candidates = self.detector.detect_header_candidates_enhanced(raw_data)
            
        print(f"\næ£€æµ‹åˆ° {len(candidates)} ä¸ªå€™é€‰æ ‡é¢˜è¡Œ")
        for i, candidate in enumerate(candidates):
            print(f"å€™é€‰ {i+1}: è¡Œ {candidate['row_index']}, ç½®ä¿¡åº¦ {candidate['confidence']:.3f}")
        
        # éªŒè¯ç»“æœ
        self.assertIsInstance(candidates, list)
        
        # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°å€™é€‰ï¼Œè¾“å‡ºè°ƒè¯•ä¿¡æ¯
        if len(candidates) == 0:
            print("\nè°ƒè¯•ä¿¡æ¯: åˆ†ææ¯ä¸€è¡Œ")
            for i, row in enumerate(raw_data[:5]):  # åªæ£€æŸ¥å‰5è¡Œ
                if row and not all(cell is None or str(cell).strip() == '' for cell in row):
                    analysis = self.detector.analyze_row_content_enhanced(row)
                    print(f"è¡Œ {i}: ç½®ä¿¡åº¦ {analysis['title_confidence']:.3f}, å†…å®¹: {row}")
            print("å¯èƒ½éœ€è¦è°ƒæ•´é˜ˆå€¼æˆ–æµ‹è¯•æ•°æ®")
        else:
            self.assertTrue(len(candidates) > 0, "åº”è¯¥æ£€æµ‹åˆ°è‡³å°‘ä¸€ä¸ªå¤´éƒ¨å€™é€‰")
    
    def test_calculate_position_weight(self):
        """æµ‹è¯•ä½ç½®æƒé‡è®¡ç®—"""
        print("\n=== æµ‹è¯•ä½ç½®æƒé‡è®¡ç®— ===")
        
        # æµ‹è¯•ä¸åŒä½ç½®çš„æƒé‡ï¼ˆéœ€è¦æä¾› data_start_hint å’Œ max_rows å‚æ•°ï¼‰
        data_start_hint = 5  # å‡è®¾æ•°æ®ä»ç¬¬5è¡Œå¼€å§‹
        max_rows = 20       # å‡è®¾æ€»å…±20è¡Œ
        
        weight_0 = self.detector._calculate_position_weight(0, data_start_hint, max_rows)
        weight_1 = self.detector._calculate_position_weight(1, data_start_hint, max_rows)
        weight_5 = self.detector._calculate_position_weight(5, data_start_hint, max_rows)
        weight_10 = self.detector._calculate_position_weight(10, data_start_hint, max_rows)
        
        print(f"ç¬¬0è¡Œæƒé‡: {weight_0:.3f}")
        print(f"ç¬¬1è¡Œæƒé‡: {weight_1:.3f}")
        print(f"ç¬¬5è¡Œæƒé‡: {weight_5:.3f}")
        print(f"ç¬¬10è¡Œæƒé‡: {weight_10:.3f}")
        
        # éªŒè¯æƒé‡é€’å‡
        self.assertGreater(weight_0, weight_1, "è¾ƒæ—©çš„è¡Œåº”è¯¥æœ‰æ›´é«˜çš„æƒé‡")
        self.assertGreater(weight_1, weight_5, "æƒé‡åº”è¯¥éšè¡Œå·é€’å‡")
        self.assertGreater(weight_5, weight_10, "æƒé‡åº”è¯¥éšè¡Œå·é€’å‡")
        
        # éªŒè¯æƒé‡èŒƒå›´
        for weight in [weight_0, weight_1, weight_5, weight_10]:
            self.assertGreaterEqual(weight, 0.1, "æƒé‡ä¸åº”ä½äº0.1")
            self.assertLessEqual(weight, 1.2, "æƒé‡ä¸åº”è¶…è¿‡1.2")
    
    def test_calculate_dynamic_threshold(self):
        """æµ‹è¯•åŠ¨æ€é˜ˆå€¼è®¡ç®—"""
        print("\n=== æµ‹è¯•åŠ¨æ€é˜ˆå€¼è®¡ç®— ===")
        
        # æµ‹è¯•ä¸åŒè¡Œä½ç½®çš„åŠ¨æ€é˜ˆå€¼
        data_start_hint = 5  # å‡è®¾æ•°æ®ä»ç¬¬5è¡Œå¼€å§‹
        
        threshold_0 = self.detector._calculate_dynamic_threshold(0, data_start_hint)
        threshold_2 = self.detector._calculate_dynamic_threshold(2, data_start_hint)
        threshold_5 = self.detector._calculate_dynamic_threshold(5, data_start_hint)
        threshold_10 = self.detector._calculate_dynamic_threshold(10, data_start_hint)
        
        print(f"ç¬¬0è¡Œé˜ˆå€¼: {threshold_0:.3f}")
        print(f"ç¬¬2è¡Œé˜ˆå€¼: {threshold_2:.3f}")
        print(f"ç¬¬5è¡Œé˜ˆå€¼: {threshold_5:.3f}")
        print(f"ç¬¬10è¡Œé˜ˆå€¼: {threshold_10:.3f}")
        
        # éªŒè¯é˜ˆå€¼é€’å¢è¶‹åŠ¿ï¼ˆåé¢çš„è¡Œéœ€è¦æ›´é«˜çš„ç½®ä¿¡åº¦ï¼‰
        self.assertLessEqual(threshold_0, threshold_5, "å‰é¢çš„è¡Œåº”è¯¥æœ‰æ›´ä½çš„é˜ˆå€¼")
        self.assertLessEqual(threshold_5, threshold_10, "åé¢çš„è¡Œåº”è¯¥æœ‰æ›´é«˜çš„é˜ˆå€¼")
        
        # éªŒè¯é˜ˆå€¼èŒƒå›´
        for threshold in [threshold_0, threshold_2, threshold_5, threshold_10]:
            self.assertGreaterEqual(threshold, 0.2, "é˜ˆå€¼ä¸åº”ä½äº0.2")
            self.assertLessEqual(threshold, 0.5, "é˜ˆå€¼ä¸åº”è¶…è¿‡0.5")
    
    def test_filter_false_positives(self):
        """æµ‹è¯•å‡é˜³æ€§è¿‡æ»¤"""
        print("\n=== æµ‹è¯•å‡é˜³æ€§è¿‡æ»¤ ===")
        
        # åˆ›å»ºåŒ…å«å‡é˜³æ€§çš„å€™é€‰åˆ—è¡¨ï¼ˆéœ€è¦åŒ…å« analysis å­—æ®µï¼‰
        candidates_with_false_positives = [
            {'row_index': 0, 'confidence': 0.9, 'analysis': {'non_empty_count': 5, 'numeric_count': 0, 'unique_count': 5}},
            {'row_index': 1, 'confidence': 0.8, 'analysis': {'non_empty_count': 4, 'numeric_count': 0, 'unique_count': 4}},
            {'row_index': 2, 'confidence': 0.7, 'analysis': {'non_empty_count': 3, 'numeric_count': 0, 'unique_count': 3}},
            {'row_index': 10, 'confidence': 0.6, 'analysis': {'non_empty_count': 6, 'numeric_count': 6, 'unique_count': 6}}, # å…¨æ•°å€¼è¡Œ
            {'row_index': 15, 'confidence': 0.5, 'analysis': {'non_empty_count': 1, 'numeric_count': 0, 'unique_count': 1}}, # ç¨€ç–è¡Œ
        ]
        
        # åˆ›å»ºæ¨¡æ‹Ÿçš„åŸå§‹æ•°æ®
        mock_raw_data = [[''] * 6 for _ in range(20)]  # 20è¡Œ6åˆ—çš„ç©ºæ•°æ®
        filtered = self.detector._filter_false_positives(candidates_with_false_positives, mock_raw_data)
        
        print(f"è¿‡æ»¤å‰å€™é€‰æ•°: {len(candidates_with_false_positives)}")
        print(f"è¿‡æ»¤åå€™é€‰æ•°: {len(filtered)}")
        
        # éªŒè¯è¿‡æ»¤æ•ˆæœ
        self.assertLessEqual(len(filtered), len(candidates_with_false_positives), 
                           "è¿‡æ»¤åçš„å€™é€‰æ•°åº”è¯¥ä¸è¶…è¿‡åŸå§‹æ•°é‡")
        
        # éªŒè¯é«˜ç½®ä¿¡åº¦çš„å€™é€‰è¢«ä¿ç•™
        filtered_indices = [c['row_index'] for c in filtered]
        self.assertIn(0, filtered_indices, "é«˜ç½®ä¿¡åº¦çš„ç¬¬0è¡Œåº”è¯¥è¢«ä¿ç•™")
        self.assertIn(1, filtered_indices, "é«˜ç½®ä¿¡åº¦çš„ç¬¬1è¡Œåº”è¯¥è¢«ä¿ç•™")
    
    def test_analyze_row_content_enhanced(self):
        """æµ‹è¯•å¢å¼ºçš„è¡Œå†…å®¹åˆ†æ"""
        print("\n=== æµ‹è¯•å¢å¼ºçš„è¡Œå†…å®¹åˆ†æ ===")
        
        # æµ‹è¯•ä¸åŒç±»å‹çš„è¡Œ
        header_row = ['é”€å”®æ•°æ®', 'é”€å”®æ•°æ®', 'æˆæœ¬æ•°æ®', 'æˆæœ¬æ•°æ®', '', '']
        data_row = ['100', '1000', '80', '800', '600', '480']
        mixed_row = ['äº§å“A', '100', 'äº§å“B', '200', '2023-01-01', 'N/A']
        
        header_analysis = self.detector.analyze_row_content_enhanced(header_row)
        data_analysis = self.detector.analyze_row_content_enhanced(data_row)
        mixed_analysis = self.detector.analyze_row_content_enhanced(mixed_row)
        
        print(f"å¤´éƒ¨è¡Œåˆ†æ: {header_analysis}")
        print(f"æ•°æ®è¡Œåˆ†æ: {data_analysis}")
        print(f"æ··åˆè¡Œåˆ†æ: {mixed_analysis}")
        
        # éªŒè¯åˆ†æç»“æœåŒ…å«å¿…è¦å­—æ®µ
        required_fields = ['non_empty_count', 'unique_count', 'numeric_count', 
                          'text_count', 'pattern_diversity', 'semantic_scores',
                          'date_count', 'structure_score', 'format_consistency']
        
        for analysis in [header_analysis, data_analysis, mixed_analysis]:
            for field in required_fields:
                self.assertIn(field, analysis, f"åˆ†æç»“æœåº”åŒ…å«å­—æ®µ: {field}")
        
        # éªŒè¯å¤´éƒ¨è¡Œçš„ç‰¹å¾
        self.assertGreater(header_analysis['text_count'], data_analysis['text_count'],
                          "å¤´éƒ¨è¡Œåº”è¯¥åŒ…å«æ›´å¤šæ–‡æœ¬")
        self.assertGreater(data_analysis['numeric_count'], header_analysis['numeric_count'],
                          "æ•°æ®è¡Œåº”è¯¥åŒ…å«æ›´å¤šæ•°å­—")
    
    def test_detect_multi_level_structure_enhanced(self):
        """æµ‹è¯•å¢å¼ºçš„å¤šçº§ç»“æ„æ£€æµ‹"""
        print("\n=== æµ‹è¯•å¢å¼ºçš„å¤šçº§ç»“æ„æ£€æµ‹ ===")
        
        mock_file_path = "/test/data.xlsx"
        
        # åˆ›å»ºæ¨¡æ‹Ÿçš„å¤´éƒ¨å€™é€‰å’Œåˆå¹¶å•å…ƒæ ¼ä¿¡æ¯
        mock_header_candidates = [
            {'row_index': 1, 'confidence': 0.8, 'analysis': {'non_empty_count': 4, 'text_count': 4}},
            {'row_index': 2, 'confidence': 0.7, 'analysis': {'non_empty_count': 6, 'text_count': 6}},
            {'row_index': 3, 'confidence': 0.6, 'analysis': {'non_empty_count': 6, 'text_count': 6}}
        ]
        mock_merged_cells = []
        
        result = self.detector.detect_multi_level_structure_enhanced(mock_header_candidates, mock_merged_cells)
        
        print(f"å¤šçº§ç»“æ„æ£€æµ‹ç»“æœ: {result}")
        
        # éªŒè¯ç»“æœç»“æ„
        self.assertIsInstance(result, dict)
        self.assertIn('is_multi_level', result)
        self.assertIn('confidence', result)
        self.assertIn('structure_type', result)
        self.assertIn('recommended_header', result)
        self.assertIn('analysis_details', result)
        
        # éªŒè¯ç»“æœç±»å‹
        self.assertIsInstance(result['is_multi_level'], bool)
        self.assertIsInstance(result['confidence'], (int, float))
        self.assertIsInstance(result['structure_type'], str)
        self.assertIsInstance(result['analysis_details'], str)
        
        # éªŒè¯ç½®ä¿¡åº¦èŒƒå›´
        confidence = result['confidence']
        self.assertGreaterEqual(confidence, 0.0, "ç½®ä¿¡åº¦ä¸åº”ä½äº0")
        self.assertLessEqual(confidence, 1.0, "ç½®ä¿¡åº¦ä¸åº”è¶…è¿‡1")
    
    def test_is_numeric_helper(self):
        """æµ‹è¯•æ•°å­—æ£€æµ‹è¾…åŠ©å‡½æ•°"""
        print("\n=== æµ‹è¯•æ•°å­—æ£€æµ‹è¾…åŠ©å‡½æ•° ===")
        
        # æµ‹è¯•å„ç§æ•°å­—æ ¼å¼
        test_cases = [
            ('123', True),
            ('123.45', True),
            ('-123', True),
            ('1,234', True),
            ('12.34%', True),
            ('$123.45', True),
            ('abc', False),
            ('', False),
            ('123abc', False),
            ('N/A', False)
        ]
        
        for value, expected in test_cases:
            result = self.detector._is_numeric(value)
            print(f"'{value}' -> {result} (æœŸæœ›: {expected})")
            self.assertEqual(result, expected, f"'{value}' çš„æ•°å­—æ£€æµ‹ç»“æœä¸æ­£ç¡®")
    
    def test_is_date_like_helper(self):
        """æµ‹è¯•æ—¥æœŸæ£€æµ‹è¾…åŠ©å‡½æ•°"""
        print("\n=== æµ‹è¯•æ—¥æœŸæ£€æµ‹è¾…åŠ©å‡½æ•° ===")
        
        # æµ‹è¯•å„ç§æ—¥æœŸæ ¼å¼
        test_cases = [
            ('2023-01-01', True),
            ('2023/01/01', True),
            ('01-01-2023', True),
            ('Jan 1, 2023', True),
            ('2023å¹´1æœˆ1æ—¥', True),
            ('123', False),
            ('abc', False),
            ('', False)
        ]
        
        for value, expected in test_cases:
            result = self.detector._is_date_like(value)
            print(f"'{value}' -> {result} (æœŸæœ›: {expected})")
            self.assertEqual(result, expected, f"'{value}' çš„æ—¥æœŸæ£€æµ‹ç»“æœä¸æ­£ç¡®")


def run_comprehensive_test():
    """è¿è¡Œç»¼åˆæµ‹è¯•"""
    print("\n" + "="*60)
    print("å¼€å§‹å¢å¼ºå¤šçº§åˆ—å¤´æ£€æµ‹åŠŸèƒ½ç»¼åˆæµ‹è¯•")
    print("="*60)
    
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    suite = unittest.TestLoader().loadTestsFromTestCase(TestEnhancedMultiHeaderDetector)
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)
    
    # è¾“å‡ºæµ‹è¯•æ€»ç»“
    print("\n" + "="*60)
    print("æµ‹è¯•æ€»ç»“")
    print("="*60)
    print(f"è¿è¡Œæµ‹è¯•æ•°: {result.testsRun}")
    print(f"å¤±è´¥æ•°: {len(result.failures)}")
    print(f"é”™è¯¯æ•°: {len(result.errors)}")
    
    if result.failures:
        print("\nå¤±è´¥çš„æµ‹è¯•:")
        for test, traceback in result.failures:
            print(f"- {test}: {traceback}")
    
    if result.errors:
        print("\né”™è¯¯çš„æµ‹è¯•:")
        for test, traceback in result.errors:
            print(f"- {test}: {traceback}")
    
    success_rate = (result.testsRun - len(result.failures) - len(result.errors)) / result.testsRun * 100
    print(f"\næˆåŠŸç‡: {success_rate:.1f}%")
    
    return result.wasSuccessful()


if __name__ == '__main__':
    # è¿è¡Œç»¼åˆæµ‹è¯•
    success = run_comprehensive_test()
    
    if success:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¢å¼ºå¤šçº§åˆ—å¤´æ£€æµ‹åŠŸèƒ½å·¥ä½œæ­£å¸¸ã€‚")
    else:
        print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°ã€‚")
        sys.exit(1)